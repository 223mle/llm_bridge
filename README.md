â€» å…¨ç„¶ã¾ã æœªå®Œæˆ

# llm_bridge

> **ãƒ—ãƒ­ãƒã‚¤ãƒ€éä¾å­˜ã®ã‚·ãƒ³ãƒ—ãƒ« & æ‹¡å¼µå¯èƒ½ãª LLM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ãƒƒãƒ‘ãƒ¼**

â€» README.md written by o3

---

## ğŸ“– æ¦‚è¦

`llm_bridge` ã¯ **ã€Œ`provider:model` å½¢å¼ã€** ã§æŒ‡å®šã•ã‚ŒãŸä»»æ„ã® LLM ã‚’ã€ã¾ã£ãŸãåŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§å‘¼ã³å‡ºã™ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸè»½é‡ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

- **ãƒ—ãƒ­ãƒã‚¤ãƒ€éä¾å­˜ API** â€¦ `generate()` ã•ãˆçŸ¥ã£ã¦ã„ã‚Œã°è‰¯ã„
- **ãƒªãƒˆãƒ©ã‚¤æ¨™æº–è£…å‚™** â€¦ Exponential Backâ€‘off + Jitter, ä¾‹å¤–éšå±¤ã‚‚çµ±ä¸€
- **è¿½åŠ ã‚³ã‚¹ãƒˆã‚¼ãƒ­ã®æ‹¡å¼µæ€§** â€¦ Adapter ã‚’ 1 ã‚¯ãƒ©ã‚¹æ›¸ã„ã¦ `provider_registry.register()` ã™ã‚‹ã ã‘

> Deepwiki é¢¨ã«è¨€ãˆã°ã€Œ**çµç¯€ç‚¹ (Bridge) ã‚’ä¸­å¿ƒã«æ®ãˆãŸãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ã€ã€‚å¤–å´(ã‚¢ãƒ—ãƒª)ã¨å†…å´(SDK)ã®çµåˆåº¦ã‚’æœ€å°åŒ–ã—ã€ä¿å®ˆæ€§ã‚’æœ€å¤§åŒ–ã™ã‚‹è¨­è¨ˆã‚’æ¡ã£ã¦ã„ã¾ã™ã€‚

---

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
flowchart TD
    subgraph "Your Application"
        A["Domain / Useâ€‘case"]
    end

    subgraph "llm_bridge"
        direction TB
        B["Registry Layer<br/>(client_factory.py)"]
        C["Adapter Layer<br/>(adapters/*)"]
        D["Core Layer<br/>(types, retry, abc, model_id)"]
    end

    subgraph "Providers"
        E["OpenAI API"]
        F["Anthropic API"]
        G["Selfâ€‘Hosted LLM"]
    end

    A -->| provider:model | B
    B --> C
    C --> E
    C --> F
    C --> G
    D --> C
```

- **Core Layer**: å‹å®šç¾©ãƒ»ä¾‹å¤–ãƒ»ãƒªãƒˆãƒ©ã‚¤ãªã© *ä¾å­˜ã‚¼ãƒ­* ã®ç´”ç²‹ãƒ­ã‚¸ãƒƒã‚¯ã€‚
- **Adapter Layer**: å„ç¤¾ SDK ã¨ã®æ©‹æ¸¡ã—ã€‚`AbstractLLMClient` ã‚’å®Ÿè£…ã€‚
- **Registry Layer**: `provider` ã‚¹ãƒ©ãƒƒã‚°ã¨ Adapter ã‚¯ãƒ©ã‚¹ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã€‚
- **Your Application**: `from llm_bridge.registry import LLMClientFactory` ã§åˆæœŸåŒ–ã—ã€`generate()` ã‚’å©ãã ã‘ã€‚

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ (Deepâ€‘Dive)
1. `LLMClientFactory.initialize_client("openai:gpt-4o")` ã‚’å‘¼ã³å‡ºã™
2. `ModelId.parse()` ãŒ `provider=model` ã‚’æ­£è¦åŒ–
3. `provider_registry.get_adapter_cls()` ãŒé©åˆ‡ãª Adapter ã‚’è§£æ±º
4. Adapter (`OpenAIAdapter`) ãŒ **Core Layer** ã®ãƒªãƒˆãƒ©ã‚¤ã‚’ç¶™æ‰¿ã—ã¤ã¤ SDK ã‚’å‘¼ã³å‡ºã™
5. å¤±æ•—ã™ã‚Œã°ãƒªãƒˆãƒ©ã‚¤ã€æˆåŠŸã™ã‚Œã°ãƒ—ãƒ¬ãƒ¼ãƒ³ãªãƒ†ã‚­ã‚¹ãƒˆãŒè¿”ã‚‹

---

## ğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
src/llm_bridge
â”œâ”€â”€ adapters          # å„ç¤¾å‘ã‘ Adapter å®Ÿè£…
â”œâ”€â”€ core              # SDK ç„¡ä¾å­˜ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
â”œâ”€â”€ registry          # Adapter ç™»éŒ² & ç”Ÿæˆ
â””â”€â”€ __init__.py       # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå…¬é–‹ãƒã‚¤ãƒ³ãƒˆ
```

ãƒ•ã‚¡ã‚¤ãƒ« | å½¹å‰² | ä¸»ãªã‚¯ãƒ©ã‚¹
--- | --- | ---
`core/abc.py` | Adapter ãŒå®Ÿè£…ã™ã¹ãæŠ½è±¡åŸºåº• | `AbstractLLMClient`
`core/retry.py` | Exponential Backâ€‘off | `RetryStrategy`, `with_retry`
`core/types.py` | DTO & Enum å®šç¾© | `Message`, `GenerationParams`, `Role`
`adapters/openai_adapter.py` | OpenAI å°‚ç”¨ãƒ©ãƒƒãƒ‘ãƒ¼ | `OpenAIAdapter`
`registry/provider_registry.py` | Provider â†” Adapter ç™»éŒ²è¡¨ | `ProviderRegistry`
`registry/client_factory.py` | Adapter ç”Ÿæˆãƒ•ã‚¡ã‚¯ãƒˆãƒª | `LLMClientFactory`

---

## ğŸš€ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install llm_bridge  # ã¾ã  PyPI ã«å…¬é–‹ã—ã¦ã„ãªã„å ´åˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š
```

> **å¿…é ˆç’°å¢ƒå¤‰æ•°**: `OPENAI_API_KEY` (OpenAI Adapter åˆ©ç”¨æ™‚)

---

## âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

```python
from llm_bridge.registry.client_factory import LLMClientFactory
from llm_bridge.core.types import Message, GenerationParams, Role

# 1. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– (provider:model)
client = LLMClientFactory.initialize_client("openai:gpt-4o")

# 2. ä¼šè©±å±¥æ­´ã‚’çµ„ã¿ç«‹ã¦
messages = [
    Message(role=Role.system,    content="You are a helpful assistant."),
    Message(role=Role.user,      content="æ—¥æœ¬ä¸€é«˜ã„å±±ã¯ï¼Ÿ"),
]

# 3. ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (å¿…è¦ã«å¿œã˜ã¦)
params = GenerationParams(temperature=0.3)

# 4. æ¨è«–å®Ÿè¡Œ
answer = client.generate(messages, params)
print(answer)
```

---

## ğŸ”Œ ãƒ—ãƒ­ãƒã‚¤ãƒ€è¿½åŠ æ–¹æ³•

1. SDK ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸ `MyNewAdapter(AbstractLLMClient)` ã‚’ä½œæˆ
2. `provider_registry.register("myprovider", MyNewAdapter)` ã‚’å‘¼ã³å‡ºã™
3. ãƒ†ã‚¹ãƒˆã‚’æ›¸ã (`tests/adapters/test_myprovider.py`)

ã“ã‚Œã ã‘ã§ `LLMClientFactory.initialize_client("myprovider:myâ€‘model")` ãŒæ©Ÿèƒ½ã—ã¾ã™ã€‚

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆ

```bash
pytest -q
```

å˜ä½“ãƒ†ã‚¹ãƒˆã¯ **core** ã¨ **registry**ã€çµåˆãƒ†ã‚¹ãƒˆã¯ **adapters** ã‚’å¯¾è±¡ã«é…ç½®ã—ã¦ã„ã¾ã™ã€‚

---

## ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License.

---

## ğŸ™Œ Contributing

Issue / Pull Request å¤§æ­“è¿ã§ã™ã€‚Adapter è¿½åŠ æ™‚ã¯ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„ã€‚

- **SDK ä¾‹å¤– â†’ `LLMBridgeError`** ã¸å¿…ãšå¤‰æ›ã™ã‚‹
- å¤–éƒ¨ä¾å­˜ã¯ Adapter å†…ã«é–‰ã˜è¾¼ã‚ã€`core` ã¸ã®é€†ä¾å­˜ã‚’é¿ã‘ã‚‹
- `pytest --cov` ãŒ 95% ä»¥ä¸Šé€šã‚‹ã“ã¨

---

## âœ¨ FAQ

| è³ªå• | å›ç­” |
| --- | --- |
| éåŒæœŸå¯¾å¿œã¯ï¼Ÿ | ç¾åœ¨ Sync ã®ã¿ã€‚åŒä¸€ API ã§ Async ãƒ‘ã‚¹ã‚’è¿½åŠ äºˆå®šã§ã™ |
| OpenAI 0.x ç³»ã‚’ä½¿ã„ãŸã„ | `_invoke()` ã‚’æ›¸ãæ›ãˆã‚Œã°å‹•ãã¾ã™ |
| ãƒ¢ãƒ‡ãƒ«æ¯ã® Tokenizer ã¯ï¼Ÿ | ã‚¹ã‚³ãƒ¼ãƒ—å¤–ã€‚ä¸Šä½å±¤ã§ã”å¯¾å¿œãã ã•ã„ |

---

> Made with â¤ï¸  by [llm_bridge contributors]

